{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4OWwMQTDymhr"
      },
      "source": [
        "# Plant Seedling Classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0r8k33hSymhu"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gCeLQiHz3AY7"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import regularizers\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.applications import ResNet50"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dmynDmi2ymhy"
      },
      "source": [
        "### Defining the path for test and train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BLumVTO35Noz"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "data_dir_train = Path('/Users/siddhant/anaconda3/envs/train')\n",
        "data_dir_test = Path('/Users/siddhant/anaconda3/envs/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2oP_5wQ3KSB",
        "outputId": "3caff862-1a99-4e42-e3dc-16c154194269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5549\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "image_count_train = len(list(data_dir_train.glob('*/*.png')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.png')))\n",
        "print(image_count_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hiawZfZZymh0"
      },
      "source": [
        "### Load using keras.preprocessing\n",
        "\n",
        "### Creating the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ahxn76pu5uQY"
      },
      "outputs": [],
      "source": [
        "# specifying the batch size and image dimensions\n",
        "batch_size = 32\n",
        "img_height = 120\n",
        "img_width = 120\n",
        "num_classes = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynlmndGi9H37",
        "outputId": "8d32c432-bc58-4dcf-d9ee-bd8ccbb52c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5549 files belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "# creating train dataset\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, seed=123,\n",
        "                                                               image_size=(img_height, img_width), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm5Cnxvg-7wP",
        "outputId": "2d5fc696-8294-4773-8f23-40256ba9cedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 768 files belonging to 12 classes.\n"
          ]
        }
      ],
      "source": [
        "# creating validation dataset\n",
        "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
        "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_test, seed=123,\n",
        "                                                             image_size=(img_height, img_width), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using tranfer learnig to create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                24588     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23612300 (90.07 MB)\n",
            "Trainable params: 24588 (96.05 KB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "resnet_weights_path = '/Users/siddhant/anaconda3/envs/computer_vision/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "my_new_model = Sequential()\n",
        "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
        "my_new_model.add(Dense(num_classes,activation = 'softmax'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model. It is already trained\n",
        "my_new_model.layers[0].trainable = False\n",
        "\n",
        "my_new_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            "174/174 [==============================] - 68s 387ms/step - loss: 0.4876 - accuracy: 0.8425 - val_loss: 0.4052 - val_accuracy: 0.8750\n",
            "Epoch 2/13\n",
            "174/174 [==============================] - 70s 402ms/step - loss: 0.3759 - accuracy: 0.8809 - val_loss: 0.4602 - val_accuracy: 0.8294\n",
            "Epoch 3/13\n",
            "174/174 [==============================] - 69s 397ms/step - loss: 0.3160 - accuracy: 0.9036 - val_loss: 0.3113 - val_accuracy: 0.9128\n",
            "Epoch 4/13\n",
            "174/174 [==============================] - 70s 403ms/step - loss: 0.2740 - accuracy: 0.9184 - val_loss: 0.2873 - val_accuracy: 0.9128\n",
            "Epoch 5/13\n",
            "174/174 [==============================] - 73s 420ms/step - loss: 0.2397 - accuracy: 0.9301 - val_loss: 0.2369 - val_accuracy: 0.9375\n",
            "Epoch 6/13\n",
            "174/174 [==============================] - 71s 410ms/step - loss: 0.2115 - accuracy: 0.9420 - val_loss: 0.2390 - val_accuracy: 0.9258\n",
            "Epoch 7/13\n",
            "174/174 [==============================] - 71s 406ms/step - loss: 0.1884 - accuracy: 0.9515 - val_loss: 0.2089 - val_accuracy: 0.9375\n",
            "Epoch 8/13\n",
            "174/174 [==============================] - 69s 396ms/step - loss: 0.1738 - accuracy: 0.9566 - val_loss: 0.1740 - val_accuracy: 0.9648\n",
            "Epoch 9/13\n",
            "174/174 [==============================] - 69s 398ms/step - loss: 0.1599 - accuracy: 0.9578 - val_loss: 0.1575 - val_accuracy: 0.9635\n",
            "Epoch 10/13\n",
            "174/174 [==============================] - 70s 402ms/step - loss: 0.1435 - accuracy: 0.9643 - val_loss: 0.1669 - val_accuracy: 0.9596\n",
            "Epoch 11/13\n",
            "174/174 [==============================] - 80s 458ms/step - loss: 0.1380 - accuracy: 0.9638 - val_loss: 0.1385 - val_accuracy: 0.9622\n",
            "Epoch 12/13\n",
            "174/174 [==============================] - 70s 401ms/step - loss: 0.1227 - accuracy: 0.9712 - val_loss: 0.1383 - val_accuracy: 0.9688\n",
            "Epoch 13/13\n",
            "174/174 [==============================] - 72s 412ms/step - loss: 0.1170 - accuracy: 0.9742 - val_loss: 0.1337 - val_accuracy: 0.9674\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2b1748650>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 13\n",
        "batch_size = 32\n",
        "my_new_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "my_new_model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
